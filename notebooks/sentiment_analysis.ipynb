{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sentiments looks like this:\n",
    "# [['ausdauer', 'ausdauernd', 'ausdauernde', 0.4], ...]\n",
    "import re\n",
    "sentiments = {}\n",
    "\n",
    "regex = re.compile('^(\\w+)\\|\\s+(-?\\d+\\.\\d+)$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_sentiment(line):\n",
    "    line = line.lower()\n",
    "    main_re = re.compile(r'^([a-zäöüß]+)', re.IGNORECASE)\n",
    "    sentiment_re = re.compile(r'(-?\\d+.\\d+)')\n",
    "    forms_re = re.compile(r'([a-zäöüß,]+)$', re.IGNORECASE)\n",
    "    \n",
    "    sentiment = float(sentiment_re.findall(line)[0])\n",
    "    result = main_re.findall(line)\n",
    "    sentiments[result[0]] = sentiment\n",
    "    permutations = [f.split(',') for f in forms_re.findall(line)]\n",
    "    if permutations:\n",
    "        for p in permutations[0]:\n",
    "            sentiments[p] = sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parse_sentiment('Unglück|NN\t-0.5004\tUnglückes,Unglücks,Unglücke,Unglücken')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('SentiWS_v1.8c/SentiWS_v1.8c_Positive.txt') as file:\n",
    "    for line in file:\n",
    "        parse_sentiment(line)\n",
    "\n",
    "with open('SentiWS_v1.8c/SentiWS_v1.8c_Negative.txt') as file:\n",
    "    for line in file:\n",
    "        parse_sentiment(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sentiment(text):\n",
    "    words = [t.lower() for t in text.replace('.', '').replace(',', '').replace(';', '').split()]\n",
    "    sentiment = 0\n",
    "    matches = 0\n",
    "    for w in words:\n",
    "        s = sentiments.get(w)\n",
    "        if s:\n",
    "            sentiment += s\n",
    "            matches += 1\n",
    "    if matches:\n",
    "        return sentiment / matches\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4445"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiment(\"Lob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0813"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiment(\"belohnung\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# here we go; split each text into pieces of 500 words and calculate the sentiments\n",
    "def calculate_sentiment(file, step_size=500):\n",
    "    with open(file) as f:\n",
    "        content = f.read().split()\n",
    "        start = 0\n",
    "        results = []\n",
    "        while start < len(content):\n",
    "            words = content[start:(start+step_size)]\n",
    "            results.append(get_sentiment(' '.join(words)))\n",
    "            start += step_size\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "\n",
    "for path in glob.glob('./dumps/texts/*'):\n",
    "    filename = path.split('/')[-1]\n",
    "    identifier = filename.split('.')[0]\n",
    "    with open('./dumps/sentiment/{}.json'.format(identifier), 'w') as f:\n",
    "        f.write(json.dumps(calculate_sentiment(path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3621"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiment(\"Die Wirtschaft steckt in der Krise.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.41835"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiment(\"Ein fürchterliches Unglück ist über uns gekommen.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
